{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "marketing-subs-model-creation3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1JtfGJ-NY-xN6x9oR9ZWQ6oGuvlb52ihb",
      "authorship_tag": "ABX9TyPxQW0hKYaeN3Zd+PZPfN2T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shambhavithakur/marketing-subscription-predictor/blob/main/marketing_subs_model_creation3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li2CbOw2vBGF"
      },
      "source": [
        "# Predicting whether or not a customer will purchase a marketing subscription: Model creation with plain Scikit-Learn [3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGGJ6ACcQ7BL"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook, we will train models using selected features from the prepared dataset. To find out how this dataset was prepared, refer to the [exploratory data analysis notebook](https://colab.research.google.com/github/shambhavithakur/marketing-subscription-predictor/blob/main/marketing_subs_eda.ipynb).\n",
        "\n",
        "As the target variable in the dataset is imbalanced, we will train a few tree-based models, Gaussian Naive Bayes (GaussianNB), Gradient Boosting Classifier (GBC), Ada Boost Classifier (ABC), Decision Tree Classifier (DTC), Random Forest Classifier (RFC), and XGBoost, on the data. Compared to other types of models, tree-based models generate more accurate predictions on imbalanced&nbsp;data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw53DIhYwM5u"
      },
      "source": [
        "## Loading the training data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "drp919l8LsDG"
      },
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 3)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.float_format', '{:.3f}'.format)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVnxzkABulz7"
      },
      "source": [
        "# Using pandas to load the dataset\n",
        "\n",
        "base_path = '/content/drive/MyDrive/ml/20201015-marketing-subs/'\n",
        "\n",
        "train = pd.read_feather(base_path + 'train')\n",
        "test = pd.read_feather(base_path + 'test')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvrnarPjRjNP"
      },
      "source": [
        "# Creating copies of the train and test data sets with selected features\n",
        "\n",
        "selected_features = ['age', 'job', 'marital', 'education', 'default', 'housing',\\\n",
        "                     'loan', 'contact', 'day_of_week', 'day_of_week_cos',\\\n",
        "                     'campaign', 'previous', 'poutcome', 'cons_conf_idx',\\\n",
        "                     'euribor3m', 'nr_employed', 'bought']\n",
        "\n",
        "train_v2 = train[selected_features].copy()\n",
        "test_v2 = test[selected_features].copy()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUUj2si5F_1w",
        "outputId": "3bee7e09-cde0-4bc0-8490-11cda139d930"
      },
      "source": [
        "train_v2.shape, test_v2.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35511, 17), (3946, 17))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rvSmrWxGA4A",
        "outputId": "eb2d0d08-d4af-4ba6-88e3-645babffe44c"
      },
      "source": [
        "train_v2.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35511 entries, 0 to 35510\n",
            "Data columns (total 17 columns):\n",
            " #   Column           Non-Null Count  Dtype   \n",
            "---  ------           --------------  -----   \n",
            " 0   age              35507 non-null  float64 \n",
            " 1   job              35511 non-null  category\n",
            " 2   marital          35511 non-null  category\n",
            " 3   education        35511 non-null  category\n",
            " 4   default          35511 non-null  category\n",
            " 5   housing          35511 non-null  category\n",
            " 6   loan             35511 non-null  category\n",
            " 7   contact          35506 non-null  category\n",
            " 8   day_of_week      35511 non-null  category\n",
            " 9   day_of_week_cos  35511 non-null  category\n",
            " 10  campaign         35511 non-null  int64   \n",
            " 11  previous         35511 non-null  category\n",
            " 12  poutcome         35511 non-null  category\n",
            " 13  cons_conf_idx    35511 non-null  float64 \n",
            " 14  euribor3m        35511 non-null  float64 \n",
            " 15  nr_employed      35511 non-null  category\n",
            " 16  bought           35511 non-null  category\n",
            "dtypes: category(13), float64(3), int64(1)\n",
            "memory usage: 1.5 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAK55WiPT-CO"
      },
      "source": [
        "## Subsetting the training data into training and validation subsets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pewhHuwT89d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "seed = 42\n",
        "\n",
        "X = train_v2.drop('bought', axis=1)\n",
        "y = train_v2.copy().bought\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOWTPPuzSSzT"
      },
      "source": [
        "## Separating numerical and categorical columns\n",
        "\n",
        "In the subsequent steps, we intend to use Scikit-Learn pipelines to impute missing data into the datasets. Scikit-Learn has different imputers for numerical and categorical data. Each of these imputers requires a list containing the names of the columns that it must impute. Therefore, it is imperative that we create separate lists of numerical and categorical columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3dJUtXUM0re"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "categorical_cols = list(X.select_dtypes(include=['object', 'category']).columns)\n",
        "numerical_cols = list(X.select_dtypes(include=[np.number]).columns)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE0Tjq4hSkVd"
      },
      "source": [
        "## Training GaussianNB, GBC, ABC, DTC, and RFC models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-BDJrf8TQuA"
      },
      "source": [
        "# Importing relevant modules\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, MaxAbsScaler\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDU9UzAjTdEP"
      },
      "source": [
        "# Creating a preprocessor to impute missing values\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numerical_cols),\n",
        "    ('cat', categorical_transformer, categorical_cols)\n",
        "])\n",
        "\n",
        "# Setting up recursive feature elimination (RFE) to make sure features are selected \n",
        "# by recursively considering smaller and smaller sets of features\n",
        "rfe = RFE(estimator=LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000),\\\n",
        "          n_features_to_select=7)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2C-9i1KZ0T2"
      },
      "source": [
        "# Writing a function to determine accuracy, F1 score, and \n",
        "# area under the ROC curve (AUROC)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def get_metrics(model, model_name, X=X, y=y, test=test_v2, target='bought'):\n",
        "    # Splitting test data\n",
        "    test_X = test.drop(target, axis=1)\n",
        "    test_y = test.copy()[target]\n",
        "    \n",
        "    # Fitting model on entire training data\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Obtaining prediction on new data\n",
        "    y_pred = model.predict(test_X)\n",
        "\n",
        "    print(f'Data about the {model_name} model:')\n",
        "\n",
        "    # Finding out whether the model is predicting both classes\n",
        "    print(f'Classes predicted by the model: {np.unique(y_pred)}')\n",
        "\n",
        "    # Calculating accuracy score\n",
        "    print(f'Accuracy score: {accuracy_score(test_y, y_pred):.3f}')\n",
        "\n",
        "    # Calculating F1 score\n",
        "    print(f'F1 score: {f1_score(test_y, y_pred):.3f}')\n",
        "\n",
        "    # Determining AUROC\n",
        "    y_prob = model.predict_proba(test_X)\n",
        "    y_prob = [p[1] for p in y_prob]\n",
        "    print(f'AUROC of the model: {roc_auc_score(test_y, y_prob):.3f}')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nJX9q7tu3BP",
        "outputId": "d09c8f89-9334-42c4-dbc4-6b515bf8f8a9"
      },
      "source": [
        "# Training a GaussianNB model\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "class DenseTransformer(TransformerMixin):\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None, **fit_params):\n",
        "        return X.todense()\n",
        "\n",
        "pipe_gnb = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('feat_selector', rfe),\n",
        "                           ('to_dense', DenseTransformer()),\n",
        "                           ('gnb', GaussianNB())\n",
        "                          ])\n",
        "\n",
        "mod_gnb = pipe_gnb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the GaussianNB model\n",
        "get_metrics(mod_gnb, 'GaussianNB')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data about the GaussianNB model:\n",
            "Classes predicted by the model: [0 1]\n",
            "Accuracy score: 0.878\n",
            "F1 score: 0.395\n",
            "AUROC of the model: 0.745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWClEsZb4ygy",
        "outputId": "b2bebf71-5486-4864-ffa9-eadd3b6de0ce"
      },
      "source": [
        "# Training an ABC model\n",
        "pipe_abc = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('feat_selector', rfe),\n",
        "                           ('abc', AdaBoostClassifier(random_state=seed,\\\n",
        "                                                      n_estimators=500))\n",
        "                          ])\n",
        "\n",
        "mod_abc = pipe_abc.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the ABC model\n",
        "get_metrics(mod_abc, 'ABC')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data about the ABC model:\n",
            "Classes predicted by the model: [0 1]\n",
            "Accuracy score: 0.885\n",
            "F1 score: 0.295\n",
            "AUROC of the model: 0.746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6REaxzam44m7"
      },
      "source": [
        "# Training a DTC model\n",
        "pipe_dtc = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('maxabs', MaxAbsScaler()),\n",
        "                           ('feat_selector', rfe),\n",
        "                           ('dtc', DecisionTreeClassifier(max_features='log2',\\\n",
        "                                                          random_state=seed))\n",
        "                           ])\n",
        "\n",
        "mod_dtc = pipe_dtc.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the DTC model\n",
        "get_metrics(mod_dtc, 'DTC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1B49MVf48m3"
      },
      "source": [
        "# Training an RFC model\n",
        "pipe_rfc = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('feat_selector', rfe),\n",
        "                           ('rfc', RandomForestClassifier(n_estimators=500,\\\n",
        "                                                          max_features=0.9,\\\n",
        "                                                          random_state=seed))\n",
        "                           ])\n",
        "\n",
        "mod_rfc = pipe_rfc.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the RFC model\n",
        "get_metrics(mod_rfc, 'RFC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzCZiH0p5CRZ"
      },
      "source": [
        "# Training a GBC model\n",
        "pipe_gbc = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('feat_selector', rfe),\n",
        "                           ('gbc', GradientBoostingClassifier(random_state=seed,\\\n",
        "                                                              max_depth=5,\\\n",
        "                                                              n_estimators=500,\\\n",
        "                                                              warm_start=True,\\\n",
        "                                                              n_iter_no_change=10))\n",
        "                          ])\n",
        "\n",
        "mod_gbc = pipe_gbc.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the GBC model\n",
        "get_metrics(mod_gbc, 'GBC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuqzCuOB3673",
        "outputId": "4c539b65-cb22-48f3-bd99-b2b37592da32"
      },
      "source": [
        "# Training an XGBoost classifier using random search\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numerical_cols),\n",
        "    ('cat', categorical_transformer, categorical_cols),\n",
        "])\n",
        "\n",
        "pipe_grid = Pipeline([('preprocessor', preprocessor), ('feat_selector', rfe)])\n",
        "\n",
        "xgb = XGBClassifier(tree_method='gpu_hist', max_bin=16, verbosity=0)\n",
        "\n",
        "pipe_xgb = Pipeline([('xgb', xgb)])\n",
        "\n",
        "prams={\n",
        "    'xgb__learning_rate': [0.01,0.03,0.05,0.1,0.15,0.2],\n",
        "    'xgb__n_estimators': [100,200,500,1000,2000],\n",
        "    'xgb__max_depth': [3,5,10],\n",
        "    'xgb__colsample_bytree': [0.1,0.3,0.5,1],\n",
        "    'xgb__subsample': [0.1,0.3,0.5,1]\n",
        "}\n",
        "\n",
        "searcher = RandomizedSearchCV(pipe_xgb, param_distributions=prams, verbose=10, n_iter=20, \\\n",
        "                              random_state=seed, cv=10, scoring='roc_auc', n_jobs=-1,\\\n",
        "                              error_score=0, refit=True)\n",
        "\n",
        "random_search_xgb = make_pipeline(pipe_grid, searcher)\n",
        "random_search_xgb.fit(X_train, y_train) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.5s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   28.5s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   33.1s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   45.1s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  8.8min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  9.6min\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  9.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('pipeline',\n",
              "                 Pipeline(memory=None,\n",
              "                          steps=[('preprocessor',\n",
              "                                  ColumnTransformer(n_jobs=None,\n",
              "                                                    remainder='drop',\n",
              "                                                    sparse_threshold=0.3,\n",
              "                                                    transformer_weights=None,\n",
              "                                                    transformers=[('num',\n",
              "                                                                   Pipeline(memory=None,\n",
              "                                                                            steps=[('imputer',\n",
              "                                                                                    SimpleImputer(add_indicator=False,\n",
              "                                                                                                  copy=True,\n",
              "                                                                                                  fill_value=None,\n",
              "                                                                                                  missing_values=nan,\n",
              "                                                                                                  strategy='median',\n",
              "                                                                                                  verbose=0)),\n",
              "                                                                                   ('sc...\n",
              "                                    iid='deprecated', n_iter=20, n_jobs=-1,\n",
              "                                    param_distributions={'xgb__colsample_bytree': [0.1,\n",
              "                                                                                   0.3,\n",
              "                                                                                   0.5,\n",
              "                                                                                   1],\n",
              "                                                         'xgb__learning_rate': [0.01,\n",
              "                                                                                0.03,\n",
              "                                                                                0.05,\n",
              "                                                                                0.1,\n",
              "                                                                                0.15,\n",
              "                                                                                0.2],\n",
              "                                                         'xgb__max_depth': [3,\n",
              "                                                                            5,\n",
              "                                                                            10],\n",
              "                                                         'xgb__n_estimators': [100,\n",
              "                                                                               200,\n",
              "                                                                               500,\n",
              "                                                                               1000,\n",
              "                                                                               2000],\n",
              "                                                         'xgb__subsample': [0.1,\n",
              "                                                                            0.3,\n",
              "                                                                            0.5,\n",
              "                                                                            1]},\n",
              "                                    pre_dispatch='2*n_jobs', random_state=42,\n",
              "                                    refit=True, return_train_score=False,\n",
              "                                    scoring='roc_auc', verbose=10))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lT-ak-B9Dxf",
        "outputId": "a27c801f-691c-40bc-f1a1-d23e68ea28dd"
      },
      "source": [
        "# Evaluating the XGBoost model\n",
        "get_metrics(random_search_xgb, 'XGBoost')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   10.7s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   26.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   30.9s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   42.9s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   59.8s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  8.8min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  9.6min\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  9.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data about the XGBoost model:\n",
            "Classes predicted by the model: [0 1]\n",
            "Accuracy score: 0.885\n",
            "F1 score: 0.295\n",
            "AUROC of the model: 0.746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-vtv6EY9XiH"
      },
      "source": [
        "## Saving models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ATx4Feo9ZWH",
        "outputId": "5c900ca6-62d9-40d0-8eff-95a9e1c1ebde"
      },
      "source": [
        "from joblib import dump\n",
        "dump(mod_gnb, 'gaussiangb_plain_sklearn.joblib')\n",
        "dump(random_search_xgb, 'random_search_xgb_plain_sklearn.joblib')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['random_search_xgb_plain_sklearn.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlLzH3Dn-rWY"
      },
      "source": [
        "## Loading the saved GaussianGB model and making a prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCs9mcH1EIST"
      },
      "source": [
        "# Defining a function to get prediction from a loaded model\n",
        "\n",
        "def get_prediction_loaded_model(model, model_name, test, target='bought'):\n",
        "    # Splitting test data\n",
        "    test_X = test.drop(target, axis=1)\n",
        "\n",
        "    # Obtaining prediction on new data\n",
        "    y_pred = model.predict(test_X)\n",
        "\n",
        "    print(f'{model_name} prediction: {y_pred}')\n",
        "\n",
        "    print('\\nThe prediction is for the following data:')\n",
        "    print(test.head())\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEeZ1W9N-Pu3",
        "outputId": "432a1aa4-03c0-4026-c9a2-afe050350336"
      },
      "source": [
        "from joblib import load\n",
        "\n",
        "loaded_gaussiangb_plain_sklearn = load('gaussiangb_plain_sklearn.joblib')\n",
        "\n",
        "get_prediction_loaded_model(loaded_gaussiangb_plain_sklearn, 'Loaded GaussianGB', test_v2[3:5])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded GaussianGB prediction: [0 0]\n",
            "\n",
            "The prediction is for the following data:\n",
            "     age                        job  marital          education  default housing loan   contact day_of_week day_of_week_cos  campaign previous     poutcome  cons_conf_idx  euribor3m nr_employed bought\n",
            "3 34.000              self_employed   single       basic_school       no      no   no  cellular           1           0.309         1        0  nonexistent        -42.000      4.153    5195.800      0\n",
            "4 36.000  administration_management  married  university.degree  unknown      no   no  cellular           0           1.000         4        0  nonexistent        -36.100      4.963    5228.100      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECm8K5YFNGgB",
        "outputId": "9341fe91-4fe8-43e2-a0d0-1abb1b0ba2ed"
      },
      "source": [
        "# Making another set of predictions\n",
        "loaded_gaussiangb_plain_sklearn.predict(test_v2.loc[31:35, test_v2.columns[0:-1]])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqzeuLkBN_wM",
        "outputId": "52ab8d10-d3ac-4638-d1f4-341ac1fb7b66"
      },
      "source": [
        "test_v2.loc[31:35, :].bought.values"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 0, 0, 0]\n",
              "Categories (2, int64): [0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ1NpZZrCsbJ"
      },
      "source": [
        "## Loading the saved XBGBoost model and making a prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owP3fY-0CrnF",
        "outputId": "78bf6f34-cd5b-488e-f724-2819fe9ceb01"
      },
      "source": [
        "loaded_random_search_xgb = load('random_search_xgb_plain_sklearn.joblib')\n",
        "\n",
        "get_prediction_loaded_model(loaded_random_search_xgb, 'Loaded XGBoost', test_v2[3:5])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded XGBoost prediction: [0 0]\n",
            "\n",
            "The prediction is for the following data:\n",
            "     age                        job  marital          education  default housing loan   contact day_of_week day_of_week_cos  campaign previous     poutcome  cons_conf_idx  euribor3m nr_employed bought\n",
            "3 34.000              self_employed   single       basic_school       no      no   no  cellular           1           0.309         1        0  nonexistent        -42.000      4.153    5195.800      0\n",
            "4 36.000  administration_management  married  university.degree  unknown      no   no  cellular           0           1.000         4        0  nonexistent        -36.100      4.963    5228.100      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kzuj3JiPBTq",
        "outputId": "593c9727-ba77-4082-966e-01da9d843155"
      },
      "source": [
        "# Making another set of predictions\n",
        "loaded_random_search_xgb.predict(test_v2.loc[31:35, test_v2.columns[0:-1]])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    }
  ]
}